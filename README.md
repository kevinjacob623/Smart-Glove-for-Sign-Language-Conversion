# Smart-Glove-for-Sign-Languag-Conversion
The project involves using a flex sensor and Arduino to detect hand gestures, which are then translated into letters, forming words that are transmitted via Bluetooth to a mobile app capable of both displaying the word and converting spoken words into text messages.


Smart Speaking System for Hearing and Speech Impaired: README**

Welcome to the GitHub repository for our Smart Speaking System project aimed at assisting individuals with hearing and speech impairments. This README serves as a guide to understand the project, its goals, implementation, and how to contribute.

Project Overview:
Our project aims to develop a smart speaking system that facilitates communication for individuals with hearing and speech impairments. By leveraging hand gestures and speech recognition technology, we aim to bridge the communication gap between the hearing and speech impaired individuals and the general population.

Features:
1. Flex Sensor Gesture Recognition**: Accurately detects hand gestures using flex sensors and maps them to corresponding letters for forming words.
2. Bluetooth Communication**: Utilizes the HC-05 Bluetooth module for wireless transmission of detected words to a mobile phone.
3. Mobile Application**: An accompanying mobile application displays transmitted words and converts spoken language into text messages.
4. Speech Recognition**: Incorporates speech recognition technology to convert spoken words into text for display and communication.

Hardware Requirements:
- ATMEGA328 Microcontroller
- Flex Sensors
- HC-05 Bluetooth Module

Implementation Details:
- Flex sensors are used to detect hand gestures, with voltage values mapped to corresponding angles using Arduino.
- Hand gestures are mapped to letters, forming words that are transmitted via Bluetooth to a mobile phone.
- A mobile application is developed to display transmitted words and convert speech signals into text messages.

Contributions:
We welcome contributions from the community to enhance the functionality, usability, and accessibility of our Smart Speaking System. Whether it's improving gesture recognition algorithms, optimizing Bluetooth communication, refining speech recognition capabilities, or enhancing the mobile application, your contributions are valuable.


Documentation:
Comprehensive documentation, including system architecture, hardware setup, software algorithms, and user instructions, is provided within the repository. We aim to ensure clarity and accessibility for all users.

Support and Maintenance:
We are committed to providing ongoing support and maintenance for the Smart Speaking System. Feel free to reach out with any questions, issues, or suggestions.

